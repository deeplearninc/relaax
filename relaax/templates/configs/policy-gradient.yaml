---
# generic PG configuration, which is fitted to default deepmind-lab or vizdoom environment from templates

version: 1.1.0
algorithm:
  name: policy_gradient

  input:
    shape: [42, 42]               # state: [height, width] or [height, width, channels]
    history: 4
    use_convolutions: true        # set to True to use convolutions to process the input

  output:
    continuous: false             # set to True to handle with continuous action type
    action_size: 4                # action size for the given environment

  hidden_sizes: [288]             # list of num_units for hidden layers
  batch_size: 6                   # maximum batch size, which need to accumulate for one update

  initial_learning_rate: 1e-4     # learning rate to use within the whole training process (Adam optimizer)
  rewards_gamma: 0.97             # rewards discount factor
