---
# DA3C configuration for Deep Mind Lab

version: 1.1.0
algorithm:
  name: da3c

  input:
    shape: [42, 42]               # state: [height, width] or [height, width, channels]
    history: 1                    # number of consecutive states to stuck to represent an input
    use_convolutions: true        # set to True to use convolutions to process the input,
                                  # it uses the set of convolutions from universe architecture by default
  output:
    continuous: false             # set to True to handle with continuous action type
    action_size: 6                # action size for the given environment

  hidden_sizes: [256]             # list of num_units for hidden fc layers
  batch_size: 20                  # experience size for one update

  use_lstm: true                  # to use LSTM instead of FF, set to the True
  max_global_step: 1e8            # amount of maximum global steps to pass through the training

  rewards_gamma: 0.99             # rewards discount factor

  initial_learning_rate: 1e-4     # initial learning rate to start the training
  use_linear_schedule: False      # set to True to use linear learning rate annealing wrt max_global_step

  optimizer: Adam                 # type of optimizer to use: Adam | RMSProp
  gradients_norm_clipping: 40.    # value to clip the gradients by its global norm

  combine_gradient: dc            # gradient's combining method: dc | fifo | average
  dc_lambda: 0.05                 # delay compensation regularization constant
