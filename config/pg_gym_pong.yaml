---

# This is an example of configuration to train Policy Gradient agent to play gym's pong game.
#
# To run this training open three terminals here and run:
# relaax-parameter-server --config ../relaax/config/pg_gym_pong.yaml
# relaax-rlx-server --config ../relaax/config/pg_gym_pong.yaml
# ../relaax/environments/OpenAI_Gym/main --rlx-server localhost:7001 --env Pong-v0

relaax-parameter-server:
  --bind: localhost:7000
  --checkpoint-dir: checkpoints/pg_gym_pong
  --log-level: WARNING
  --metrics-dir: metrics_pg_gym_pong

relaax-rlx-server:
  --bind: 0.0.0.0:7001
  --parameter-server: localhost:7000
  --log-level: WARNING

algorithm:
  path: ../relaax/algorithms/policy_grad  # path to algorithm package

  action_size: 6                  # action size for the given environment (gym's Pong)
  state_size: [84, 84]            # pass flattened or n-element list for an image-like state
  preprocess: true                # if true, input == difference from previous state
  hidden_layers_size: [200, 200]  # elements == hidden layers, each number == neurons
  batch_size: 10                  # how many steps perform before a param update
  max_global_step: 1e8            # maximum global step to stop the training when it is reached

  initial_learning_rate: 1e-4     # learning rate which we use through whole training
  entropy_beta: 0.01              # entropy regularization constant
  rewards_gamma: 0.99             # discount factor for rewards

  RMSProp:
    decay: 0.99                   # decay parameter for RMSProp
    epsilon: 1e-5                 # epsilon parameter for RMSProp (in a denominator sum to avoid NaN)
