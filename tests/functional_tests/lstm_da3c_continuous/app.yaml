environment:
  run: python training.py
  steps: 10000
  max_episodes: 1
  infinite_run: false

enable_unknown_metrics: true
metrics:
  episode_reward: true
  server_latency: true
  action: true
  mu: true
  sigma2: true
  critic: true

relaax-metrics-server:
  bind: localhost:7002
  metrics_dir: logs/metrics
  log_metrics: false
  log_level: INFO

relaax-parameter-server:
  --bind: localhost:7000
  --log-level: INFO

relaax-rlx-server:
  --bind: localhost:7001
  --log-level: INFO

algorithm:
  name: da3c                      # short name for algorithm to load

  input:
    shape: [1]                    # shape of input state
    history: 1                    # number of consecutive states to stack
    use_convolutions: false       # set to true to process input by convolution layers

  output:
    continuous: true             # set to true to switch to continuous action space
    loss_type: Normal             # choose loss_type by name for continuous action space
    action_size: 2                # action size for the given environment
    action_low: [0]
    action_high: [1]
    scale: 1.0                    # multiplier to scale continuous output

  hidden_sizes: [200]
  batch_size: 5                   # maximum batch size, which need to accumulate for one update

  use_icm: false                  # to use ICM, set to the True
  use_lstm: true                  # to use LSTM instead of FF, set to the True
  max_global_step: 3200000        # amount of maximum global steps to pass through the training

  entropy_beta: 0.01              # entropy regularization constant
  rewards_gamma: 0.9              # rewards discount factor
  use_gae: false                  # switcher for generalized advantage estimation
  gae_lambda: 1.0                 # lambda for generalized advantage estimation

  initial_learning_rate: 0.0001   # initial learning rate, which can be anneal by some procedure
  critic_scale: 10
  gradients_norm_clipping: false  # gradients clipping by global norm, if false then it is ignored
  optimizer: RMS                  # name of optimizer to use within training

  RMSProp:                        # RMSProp optimizer specific parameters
    decay: 0.99
    epsilon: 0.1

  ICM:                            # ICM specific parameters
    alpha: 0.1
    beta: 0.2
