---

environment:
  client: client/sample_exchange.py

metrics:
  episode_reward: true
  server_latency: true
  action: true
  mu: true
  sigma2: true
  critic: true

relaax-metrics-server:
  bind: localhost:7002
  metrics_dir: logs/metrics
  log_metrics_to_console: false
  log_level: INFO

relaax-parameter-server:
  --bind: localhost:7000
  --checkpoint-dir: training/checkpoints/sample_app
  --log-level: INFO

relaax-rlx-server:
  --bind: localhost:7001
  --log-level: DEBUG

wsproxy:
  --bind: localhost:9000

algorithm:
  path: tests/fixtures/sample/algorithms/sample
  use_system_ps: false

  action_size: 2                  # action size for the given environment
  state_size: [3]                 # array of dimensions for the input observation
  history_len: 1                  # number of observations to stack in state
  episode_len: 5                  # local loop size for one episode
  gpu: false                      # to use GPU, set to the True
  lstm: false                     # to use LSTM instead of FF, set to the True
  max_global_step: 1e8            # amount of maximum global steps to pass through the training

  initial_learning_rate: 1e-4     # 5e-5
  entropy_beta: 1e-3              # entropy regularization constant
  rewards_gamma: 0.99             # rewards discount factor
  RMSProp:
    decay: 0.99
    epsilon: 0.1
    gradient_norm_clipping: 40
